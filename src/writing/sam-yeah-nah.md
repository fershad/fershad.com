---
title: Sam, champion, yeah nah
published: 2025-06-16
summary: Some thoughts on Sam Altman's recent post "The Gentle Singularity".
---

Last week, Sam Altman published [The Gentle Singularity](https://blog.samaltman.com/the-gentle-singularity) on his blog. The post is a look towards a near future where superintelligence has been achieved. Sam's tone is along the lines of _"look, this is inevitable and really when we think about how far we've come in such a short space of time it's probably just around the corner"_. Of course he'd strike this kind of tone, given he needs to ensure people (read: investors) believe that OpenAI is still absolutely worth its valuation and the cause is worth pumping billions more dollars into.

Most of the takes I've seen about this post on my own socials pick up on the energy and water used for a ChatGPT query that Sam mentioned in his post. I'll get to that, but there are other parts of the post that I want to first touch on because, to me, they are more important (and concerning) than the far-from-transparent energy and water figures.

## Robots that can build other robots

> The economic value creation has started a flywheel of compounding infrastructure buildout to run these increasingly-powerful AI systems. And robots that can build other robots (and in some sense, datacenters that can build other datacenters) aren’t that far off.
>
> If we have to make the first million humanoid robots the old-fashioned way, but then they can operate the entire supply chain — digging and refining minerals, driving trucks, running factories, etc.—to build more robots, which can build more chip fabrication facilities, data centers, etc, then the rate of progress will obviously be quite different.
> <cite>Sam Altman - The Gentle Singularity</cite>

That's two paragraphs just to say _"line goes up, indefinitely"_.

Brother, what planet are you on? Because it sure as heck isn't the same planet that myself and 8 billion other folk are trying to inhabit. We're on a planet where resources and space are both finite. A planet that's already living well beyond its means, and [has been doing so for decades](https://overshoot.footprintnetwork.org/newsroom/past-earth-overshoot-days/). So automate away all the digging and refining you want, but tell me what happens when there's nothing left to dig and refine? When there's no more space for that next datacenter? What happens when you've taken all you can from this planet, our _only_ planet, so that robots can create more robots?

Finiteness aside, [_one does not simply add new capacity to the energy grid_](https://decarbonization.visualcapitalist.com/gridlock-visualizing-the-u-s-clean-energy-backlog/). Unless you want to [throw the humans of this planet under the bus](https://www.politico.com/news/2025/05/06/elon-musk-xai-memphis-gas-turbines-air-pollution-permits-00317582) by running unpermitted fossil fuel generation to drive those datacenter-built datacenters. Because renewables will only get you so far, and the costs of adding that plus additional baseload power for your inbred datacenter onto the grid is already [being worn by regular households](https://theconversation.com/how-your-electric-bill-may-be-paying-for-big-data-centers-energy-use-257794).

Perhaps all that's a bit harsh. Perhaps we're soon going to have a nuclear fusion future with unlimited clean energy generation for robots to make robots, datacenters to make datacenters, and for humans to ... I really dunno. I wonder if there are [any companies that would need more funding](https://www.energyconnects.com/news/renewables/2024/july/altman-s-3-7-billion-fusion-startup-leaves-scientists-puzzled/) for whom selling a future like that would be just the thing to snag some extra investor dollars, Sam?

## "We" the few

Throughout his post, Sam also talks about what "we" need to do to prepare societies for the impending superintelligence future.

> There are serious challenges to confront along with the huge upsides. _We_ do need to solve the safety issues, technically and societally, but then it’s critically important to widely distribute access to superintelligence given the economic implications. The best path forward might be something like:
>
> 1. Solve the alignment problem, meaning that we can robustly guarantee that _we_ get AI systems to learn and act towards what _we_ collectively really want over the long term.
>
> <cite>Sam Altman - The Gentle Singularity</cite>

By "we" (emphasis in the quote above is mine), I'm pretty sure that Sam isn't referring to me and you here. He's actually just meaning him and his mates in the global Tech Bro Club. Because why would they ask us? They didn't ask when they trained their huge large language models on our material, including copyrighted works. They've pretty much gotten away with that and made a pretty penny in the process too without giving any of that back to the authors, writers, creators, and other real humans whose work they stole.

So "we" means Sam and friends setting the rules by which superintelligence will be part of our future. It feels pretty sound to leave them in charge of solving safety and ethical issues on behalf of society. They've got a great track record of that, what could possibly go wrong and who could possibly be left out?

## Inference energy

> People are often curious about how much energy a ChatGPT query uses; the average query uses about 0.34 watt-hours, about what an oven would use in a little over one second, or a high-efficiency lightbulb would use in a couple of minutes. It also uses about 0.000085 gallons of water; roughly one fifteenth of a teaspoon.

As others have pointed out on social media, this is pretty much meaningless without context. What model/s do these figures refer to? What kind of operations are being performed (text-based chat, image generation, voice processing)? That level of transparency, which isn't asking for much really, coupled with more detailed data (i.e. percentiles at the least) would be amazing to see from OpenAI.

As an aside, I wonder if _one of the reasons_ OpenAI is being so closed about the inference energy consumption of their tools is because they too are reliant on the large datacenter operators to host their compute. And these providers [aren't the most forthcoming with information](https://www.thegreenwebfoundation.org/news/a-may-update-on-the-first-e-e-d-day-in-europe/) about their own energy use, even when compelled to do so by law. So it could just be that Sam doesn't know because his hosting providers can't/won't tell him. Given the billions at play here, I find that hard to believe but still possible.

So yeah
