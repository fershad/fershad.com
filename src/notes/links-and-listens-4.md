---
title: "Links and listens #4"
published: 2025-02-02
---

We had a nice little break for the Lunar New Year last week, spending some time in central Taiwan before returning home to Taipei where things were nice and quiet.

## Links

### [Build for the Web, Build on the Web, Build with the Web](https://csswizardry.com/2025/01/build-for-the-web-build-on-the-web-build-with-the-web/)

As always, Harry Roberts nails it. Rather than reaching for a framework for each new project, redesign, or update, he urges development teams to use the platform. Not only with a view to better web performance, but with a view to their longer term sanity as well.

> If I was only able to give one bit of advice to any company: iterate quickly on a slow-moving platform.

### [A selfish personal argument for releasing code as Open Source](https://simonwillison.net/2025/Jan/24/selfish-open-source/#atom-everything)

After a week off, we're back with another one from Simon Willison. Here he recaps a conversation on the Real Python podcast, in which he extols the virtues of open source code.

> I realized that one of the best things about open source software is that you can solve a problem once and then you can slap an open source license on that solution and you will never have to solve that problem ever again, no matter who’s employing you in the future.

On a related note, I also read this during the week which answered a question I've also asked many a time - [_Is “Open Source” ever hyphenated?_](https://opensource.org/blog/is-open-source-ever-hyphenated)

## Listens

### [How to Poison the A.I. Machine - Freakonomics Radio](https://freakonomics.com/podcast/how-to-poison-an-a-i-machine/)

Haha you thought we'd go a week without talking about AI. Lol. At least it's not Deepseek.

This Freakonomics episode features a conversation with Ben Zhao, whose research lab has been doing some pretty pioneering work to prevent AI misuse and protect the rights of content creators from having their work eaten up by AI training models. One approach that's covered in this episode is the idea of "poisoning" the material on which the AI is trained, so that when it's asked to reproduce something similar the AI application consistently ends up generating something that's totally incorrect.

> Art is interesting when it has intention, when there's meaning and context. So when AI tries to replace that, it has no context and meaning. Art replicated by AI, generally speaking, loses the point. It is not about automation. I think that it is a mistaken analogy that people will oftentimes bring up. They say, well you know what about the horse and buggy and the automobile? No, this is actually no about that at all. AI does not reproduce human art at a faster rate. What AI does is takes past samples of human art, shakes it in a kaleidoscope, and gives you a mixture of what has already existed before.
