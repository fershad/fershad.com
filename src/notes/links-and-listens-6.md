---
title: "Links and listens #6"
published: 2025-02-23
---

Missed last week as I was returning on a late night flight from Thailand after a Touch Football competition there on the weekend. It was my first time in Bangkok, and first time playing with the Touch community there. Met a lot of really good people who I hope to keep in contact with over the years to come!

## Links

### [“Calling In” Versus “Calling Out”](https://therippleeffecteducation.ca/calling-in-vs-calling-out/)

I came across this piece as a side effect of some internet hot drama that I was passively watching from the sidelines. I like distinctions made for when we might choose to call something/someone out versus when it could make more sense to call them in.

> According to Thom (2015), calling out is when we publicly name the harm, often responding with strong emotions like anger, drawing the attention of others to the problem. Calling in is when we privately respond to the person and gently explain why their behaviour needs to change. Both of these strategies can be effective in holding people accountable, but it is important to consider what is happening in the situation and what result you would like to achieve.

### [Debating the Merits of LLMs](https://css-irl.info/debating-the-merits-of-llms/)

[An article earlier this month by Robin Sloan](https://www.robinsloan.com/lab/is-it-okay/) has prompted a few bloggers to voice their opinions about the merits of LLMs, and the merits of the arguments Robin made in their article too. Michelle makes the point that LLMs have limited utility, mostly for processing texts and do not create new knowledge.

> Both of these applications are interesting and potentially useful. But they are not the same. An LLM as described above, while useful, shouldn’t invent new information. It processes the text that already exists, not the science behind it, and if it appears to offer up something new then that should be met with the utmost scrutiny. And it remains to be seen whether they (and others like them) will be worth the extraordinary amount of energy and resources that AI demands.

### [The Rot Economy](https://www.wheresyoured.at/the-rot-economy/)

Line doesn't always have to go up, and growth doesn't always have to mean "more".

> If you build a nice, sustainable fire, it’ll keep you warm, cook food and sustain life. And if the only thing you care about is how big your fire is, then it’ll set fire to everything around it, and the more you throw into it, the more it’ll burn. Eventually, you’ll have nothing left, but if you desperately desire that fire, you will constantly have to find new things to burn at any cost.

### [AI wants to rule the World, but it can’t handle dairy.](https://brilliantcrank.com/ai-wants-to-rule-the-world-but-it-cant-handle-dairy/)

Greg Storey recaps his time at IBM, and how messy data was/is such a big blocker for many companies ability to automate processes. The commentary on the Google Superbowl commercial made me lol.

> If Google’s AI can’t even fact-check the popularity of a cheese, how the hell is it supposed to take over someone’s job? What is the value of having an assistant that does an amazing job 60% of the time—every time? And how is it going to do good work if it can’t find the data because it’s still on spreadsheets on a laptop somewhere?

## Listens

### [Playboi Farti and his AI Homework Machine](https://www.searchengine.show/listen/search-engine-1/playboi-farti-and-his-ai-homework-machine)

Search Engine is fast becoming one of my favourite podcasts. In this episode, PJ Vogt explores the use of AI in the education system and the attempts that have been made to regulate it.

> I've seen people use image generators in amazing ways, but the reason they are able to use them in amazing ways is because they can talk to the image generator like an art director. Not like a prompt engineer, but like an art director. And these are the things that we need to be teaching people to use technology that can generate images or syntax or video or music or what have you. Not, how do you interact with this thing on a moment-to-moment basis to get an output? Because that just puts ... everything behind a veil. It's like the great Oz is back there doing stuff. We should know exactly what Oz is up to when we are asking it to do things.
